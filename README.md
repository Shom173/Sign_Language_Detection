# Sign_Language_Detection

Sign Language Detection using YOLOv5

Overview
This project utilizes the YOLOv5 object detection model to recognize and convert sign language gestures into text. It captures real-time input images, processes them using deep learning, and provides accurate sign language interpretation.

Features

> Real-time sign language detection and classification
> Custom dataset annotation using LabelImg
> Trained YOLOv5 model for high accuracy
> Supports six sign language gestures
> Efficient text conversion from detected signs

Technologies Used

> Deep Learning: YOLOv5 (CNN-based object detection model)
> Programming Languages: Python

Libraries: OpenCV, PyTorch, TensorFlow, LabelImg

Data Annotation: LabelImg for creating bounding boxes

Model Training: Transfer learning on a custom dataset
